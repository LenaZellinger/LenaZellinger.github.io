---
# Display name
title: Lena Zellinger

# Name pronunciation (optional)
#name_pronunciation: Chien Shiung Wu

# Full name (for SEO)
first_name: Lena
last_name: Zellinger

# Is this the primary user of the site?
superuser: true

# Highlight the author in author lists? (true/false)
highlight_name: true

# Role/position/tagline
role: PhD student

# Organizations/Affiliations to display in Biography blox
organizations:
  - name: University of Edinburgh

# Social network links
# Need to use another icon? Simply download the SVG icon to your `assets/media/icons/` folder.
profiles:
  - icon: at-symbol
    url: 'mailto:L.Zellinger@sms.ed.ac.uk'
  - icon: brands/x
    url: https://twitter.com/lena_zellinger
  - icon: brands/github
    url: https://github.com/LenaZellinger
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?user=JVsrfAYAAAAJ&hl=com

interests:
  - Tractable probabilistic modeling
  - Computational statistics
  - Uncertainty quantification
  - Neuro-symbolic AI

education:
  - area: PhD at the Institute for Adaptive and Neural Computation, current
    institution: University of Edinburgh
  - area: MSc in Data Science, 2022
    institution: University of Vienna
  - area: BSc in Statistics, 2020
    institution: University of Vienna
---
I am an [ELLIS](https://ellis.eu/) PhD student, supervised by [Dr. Antonio Vergari](http://nolovedeeplearning.com/) and [Dr. Nikolay Malkin](https://malkin1729.github.io/) at the University of Edinburgh, as well as [Dr. Vincent Fortuin](https://fortuin.github.io/) at Helmholtz AI and TU Munich. As such, I am a member of the [APRIL](https://april-tools.github.io/) and [ELPIS](https://fortuinlab.github.io/) research labs.

I am broadly interested in anything related to neuro-symbolic reasoning and uncertainty quantification. Specifically, I am eager to understand how and when we can satisfy constraints, such as safety rules or domain knowledge, in our deep learning systems to ensure their safe deployment in practice. At the same time, I aim to develop methods that are interpretable and computationally efficient. 

If you are excited about similar topics, feel free to reach out, as I am always happy to discuss and collaborate.